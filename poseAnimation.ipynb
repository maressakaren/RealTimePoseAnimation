{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "pose_video2 = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Carregar vídeos\n",
    "video_camera = cv2.VideoCapture(0)\n",
    "video_file = cv2.VideoCapture('media/videoplayback.mp4')\n",
    "\n",
    "# Inicializar frames\n",
    "frame_cam = None\n",
    "frame_file = None\n",
    "output_cam = None\n",
    "output_file = None\n",
    "\n",
    "# Função para processar a pose\n",
    "def detectPose(image, pose):\n",
    "    output_image = np.zeros_like(image)\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imageRGB)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
    "                                  connections=mp_pose.POSE_CONNECTIONS)\n",
    "    return output_image\n",
    "\n",
    "# Função para capturar e processar o frame da câmera\n",
    "def process_camera():\n",
    "    global frame_cam, output_cam\n",
    "    while video_camera.isOpened():\n",
    "        ok, frame = video_camera.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        frame_cam = frame\n",
    "        output_cam = detectPose(frame, pose_video)\n",
    "\n",
    "# Função para capturar e processar o frame do vídeo\n",
    "def process_video():\n",
    "    global frame_file, output_file\n",
    "    while video_file.isOpened():\n",
    "        ok2, frame2 = video_file.read()\n",
    "        if not ok2:\n",
    "            break\n",
    "        frame2 = cv2.resize(frame2, (640, 480))\n",
    "        frame_file = frame2\n",
    "        output_file = detectPose(frame2, pose_video2)\n",
    "\n",
    "# Iniciar threads\n",
    "thread_cam = threading.Thread(target=process_camera)\n",
    "thread_video = threading.Thread(target=process_video)\n",
    "\n",
    "thread_cam.start()\n",
    "thread_video.start()\n",
    "\n",
    "# Loop para exibir as janelas\n",
    "cv2.namedWindow('Video Original', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('Meu Esqueleto', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('Esqueleto do Video', cv2.WINDOW_NORMAL)\n",
    "\n",
    "while True:\n",
    "    # Mostrar os frames processados\n",
    "    if frame_cam is not None and output_cam is not None:\n",
    "        cv2.imshow('Meu Esqueleto', output_cam)\n",
    "    if frame_file is not None and output_file is not None:\n",
    "        cv2.imshow('Esqueleto do Video', output_file)       \n",
    "        cv2.imshow('Video Original', frame_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Pressionar 'q' para sair\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "video_camera.release()\n",
    "video_file.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Esperar as threads terminarem\n",
    "thread_cam.join()\n",
    "thread_video.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
